{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Imbalanced Classes\n",
    "\n",
    "Most of the datasets covered in machine learning courses are *balanced*. This is because you are learning how the algorithm works without worrying about additional information unrelated to the learning objective. When you start working with real, uncleaned data one of the first things you notice is how much noisier and imbalanced it is.\n",
    "\n",
    "This lesson is meant to provide an overview of the different methods available for handling imbalanced classes, the differences between oversmapling techniques, and avoiding the \"metric trap\".\n",
    "\n",
    "\n",
    "Some examples of imbalanced classes:\n",
    "\n",
    "* Fraud detection\n",
    "* Medical screening\n",
    "* Detecting defects in a factory\n",
    "* Ad conversation rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make better use of Jupyter Notebook cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages needed for this notebook: MLXTEND, IMBALANCED-LEARN\n",
    "#!pip install mlxtend\n",
    "#!conda install -c conda-forge imbalanced-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the usual suspects. Any new functions will be introduced individually for clarity.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n",
    "# make prettier plots\n",
    "%config InlineBackend.figure_format = 'svg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)\n",
    "\n",
    "# prints confusion matrix as a heatmap which is nicer to visaulize\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=18):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Metric Trap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/itsatrap.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Metric Trap\" is a result of training for accuracy (as most models in sklearn are wont to do). If the dataset has 1% of the data in class 1, we can predict class 0 **all the time** and get an accuracy of 99%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to unzip the train.7z file in the repo for this line to work.\n",
    "# uncomment line below to unzip file\n",
    "!7z x data/train.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_df = pd.read_csv('train.csv')\n",
    "target_count = imbalanced_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dataset to avoid accidental Git submissions\n",
    "!rm train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print class balance\n",
    "print(f'Class 0: {target_count[0]}')\n",
    "print(f'Class 1: {target_count[1]}')\n",
    "print(f'Proportion: {round(target_count[0] / target_count[1], 2)} : 1')\n",
    "print(f'Percentage of Majority Class: {round(target_count[0] / sum(target_count), 4)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count.plot(kind='bar', title='Class Count', rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can potentially happen when we build a classifier on an imbalanced dataset?**\n",
    "\n",
    "**Ans:** Worst case scenario, we predict the majority class all the time. In other times, the algorithm reaches a suboptimal decision and model performance suffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imbalanced_df.iloc[:, 2:]\n",
    "y = imbalanced_df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll go straight to a robust classifier to show even they are prone to the metric trap\n",
    "# takes ~ 1 min to run\n",
    "clf = XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {round(accuracy, 4)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm = print_confusion_matrix(conf_mat, ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we used a robust classifier, our model is essentially only predicting one class regardless of the underlying data! \n",
    "\n",
    "Let's look at different methods for handling imbalanced class datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 - Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Oversampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling does what its name implies. Takes the minority class and over-samples it until it is balanced with the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic imbalanced data \n",
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, \n",
    "                           weights=[0.04, 0.96],\n",
    "                           class_sep=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=['column1', 'column2'])\n",
    "df['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('column1', 'column2', data=df, hue='label',\n",
    "           palette='Set2', fit_reg=False, scatter_kws={'s': 20})\n",
    "plt.gcf().set_size_inches(12,8);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a classifier on this data set and plot the decision region\n",
    "clf = SVC().fit(X, y)\n",
    "plot_decision_regions(X, y, clf)\n",
    "plt.title(f'SVC with y = {Counter(y)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf.predict(X)), ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix and decision region plot above show that we are still getting the minority class wrong whenever a minority sample is close to the region where the bulk of the majority points lie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we do better? \n",
    "Yes! By oversampling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add some random oversampling of the minority classes\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yay, balanced classes!\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis again. What do we expect to see with balanced classes??\n",
    "# cell takes ~15s to run\n",
    "clf_ros = SVC().fit(X_resampled, y_resampled)\n",
    "plot_decision_regions(X_resampled, y_resampled, clf_ros)\n",
    "plt.title(f'Oversampled SVC with y = {Counter(y_resampled)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf_ros.predict(X)), ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Much better!** - just by using random oversampling, we were able to classify correctly an additional 30 minority points. Remember, this is the class we are interested in classifying correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - Synthetic Minority Oversampling TEchnique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/smote.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_smoted, y_smoted = SMOTE(random_state=42).fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classifier and plot decision region with SMOTE data\n",
    "clf_smote = SVC().fit(X_smoted, y_smoted)\n",
    "plot_decision_regions(X_smoted, y_smoted, clf_smote)\n",
    "plt.title(f'SMOTE SVC with y = {Counter(y_resampled)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf_smote.predict(X)), ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we used a different technique, we achieved the same result as random oversampling. \n",
    "\n",
    "\n",
    "**Can you explain why that was the case?**\n",
    "\n",
    "\n",
    "**Ans:** SMOTE does not differentiate between points near the decision boundary and points far away from it. Thus, it generated new points in areas that did not matter for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Exercise\n",
    "\n",
    "Another method we can try is ADASYN (ADAptive SYNthetic oversampling). Instead of generating synthetic observations between any minority points, it puts more emphasis on the regions where the class imbalance is greatest. In other words, in the regions where the classifier is most likely to predict the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ADASYN and create a new oversampled dataset\n",
    "\n",
    "## Code goes here ##\n",
    "from imblearn.over_sampling import ADASYN\n",
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that our dataset is reasonably balanced\n",
    "\n",
    "## Code goes here ##\n",
    "Counter(y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVC classifier using the data and plot the decision region\n",
    "\n",
    "## Code goes here ##\n",
    "clf_adasyn = SVC().fit(X_adasyn, y_adasyn)\n",
    "plot_decision_regions(X_adasyn, y_adasyn, clf_adasyn)\n",
    "plt.title(f'ADASYN SVC with y = {Counter(y_adasyn)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "\n",
    "## Code goes here ##\n",
    "cm = print_confusion_matrix(confusion_matrix(y, clf_adasyn.predict(X)), ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning Check\n",
    "In your opinion, which oversampling method worked best for **this** dataset? Why? \n",
    "\n",
    "**Ans:** This depends. Clearly, the model with ADASYN does better at classifying the minority class, but it also comes at the cost of misclassifying 879 observations from the majority class. If you're building a fraud detector, this might be acceptable! If detecting some unwanted medical disease, a lot of patients will have increased medical fees related to additional testing, prescription drugs, etc., which is not a good outcome. Understand the business reason and the costs associated with false positives/negatives to determine what is an acceptable trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 - Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/undersampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling is the opposite of Oversampling. It takes the majority class and under-samples it until it is balanced with the minority class.\n",
    "\n",
    "**In what scenarios would this method be useful?**\n",
    "\n",
    "**Ans:** If your model is computationally expensive and doubling the size of the data would hurt performance, undersampling would be a better approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_under, y_under = RandomUnderSampler(random_state=42).fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rus = SVC().fit(X_under, y_under)\n",
    "plot_decision_regions(X_under, y_under, clf_rus)\n",
    "plt.title(f'Undersampled SVC with y = {Counter(y_under)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf_rus.predict(X)), ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling can be a valid method to try, especially if you have large datasets and want to avoid increasing computation time. In our case, we didn't do much better by undersampling though the imbalanced learn library (`imblearn`) has additional tools/methods for undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "Let's look at what happens when there are multiple classes, one of which is highly imbalanced. Fortunately, the methods we covered for binary classification still work in a multiclass setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic imbalanced multiclass data\n",
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1, \n",
    "                           weights=[0.01, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=['column1', 'column2'])\n",
    "df['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('column1', 'column2', data=df, hue='label',\n",
    "           palette='Set1', fit_reg=False, scatter_kws={'s': 20})\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how this performs using a linear SVC\n",
    "clf = LinearSVC().fit(X, y)\n",
    "plot_decision_regions(X, y, clf)\n",
    "plt.title(f' Linear SVC with y = {Counter(y)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf.predict(X)), ['Class 0', 'Class 1', 'Class 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear SVC is still having problems with class 0 and class 1, though the effects are more drastic for class 1. \n",
    "\n",
    "How about if our model was predicting the likelihood of having a rare, but aggressive, form of cancer? Would we still be okay misclassifying ~80% of these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add some random oversampling of the minority classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our classes are balanced\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ros = LinearSVC().fit(X_resampled, y_resampled)\n",
    "plot_decision_regions(X_resampled, y_resampled, clf_ros)\n",
    "plt.title(f' Oversampled Linear SVC with y = {Counter(y_resampled)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf_ros.predict(X)), ['Class 0', 'Class 1', 'Class 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN worked well before, how about now? \n",
    "X_adasyn, y_adasyn = ADASYN().fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_smote = LinearSVC().fit(X_adasyn, y_adasyn)\n",
    "plot_decision_regions(X_smoted, y_smoted, clf_smote)\n",
    "plt.title(f'ADASYN SVC with y = {Counter(y_adasyn)}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.gcf().set_size_inches(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y, clf_smote.predict(X)), ['Class 0', 'Class 1', 'Class 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical workflow for handling imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list is helpful when dealing with imbalanced datasets.\n",
    "\n",
    "### Do Nothing!\n",
    "That's right, sometimes we'll get lucky and our classifier will deal effectively with the class imbalance. Go celebrate.\n",
    "\n",
    "### Balance the dataset in some way\n",
    "- Would you run into _serious_ computational issues by doubling the amount of data you have? If so, use **Random Undersampling**\n",
    "- If you have a lot variety in your dataset, you can try **Random Oversampling** as this method will generalize well from the minority observations you currently have.\n",
    "- If Random Oversampling didn't work as well as you had hoped, try **generating synthetic data** with SMOTE or ADASYN. \n",
    "\n",
    "\n",
    "### Switch to an Anomaly Detection Algorithm\n",
    "If the above experiments don't yield the desired results, switch to an anomaly detection algorithm (not covered in this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In this lesson we focused on tools used to tackle imbalanced datasets. They have applications in many areas in data science since most real world data is naturally imbalanced.  \n",
    "\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- The metric trap is real, even \"Kaggle-winning algorithms\" are prone to failure with highly imbalanced datasets. \n",
    "- Which method we use will be dependent on the problem. For example, sometimes ADAYSN will work great, in other cases, not so much. \n",
    "- If the dataset is small to begin with, undersampling may reduce your data too much and many classifiers will have difficulty generalizing.\n",
    "- Oversampling methods may prove to be computationally intensive depending which algorithm is being used. Find out what limitations you have an adjust accordingly.\n",
    "- Always think of the business case! Is misclassifying the majority class just as bad as misclassifying the minority class? What is the right metric for your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
